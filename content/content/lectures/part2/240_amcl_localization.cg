---
title: "Localization in practice"
desc: Look at the mechanics of SLAM and AMCL
slides: true
---
* **Reading: :topic_link :hw_119_brookspaper**

*Reminder: Readings are your responsibility. You will be expected to come to class prepared, having read the material, and ready to participate in the discussion*
:h2 Logistics

* Overall impressions of wall follower submisions
* Many algorithms looked similar. This is likely because of google, chatgpt, or student cooperation
* And if that's as far as it went, that's perfect
* You found that algorithms that work in sim dont work as is in real life. This is a well known fact.
* The sim is never going to reproduce the quirks of a TB3
* Try to modularize more
* Write functions, methods, classes or nodes to represent separable algorithms
* Especially Nodes
* Lets slook at the Lidar Scan Message a little closer.


:slide_bigtitle Localization

* I will be using these [Localization Slides](/content/topics/documents/f1slides.pdf) and information from [this very useful and in depth paper](https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume11/fox99a-html/jair-localize.html)
* Probabilistic algorithm
* See figure in PowerPoint
* Belief, Sense, Update ... etc.
* But how is the belief represented, and how is the update done efficiently

:slide_title AMCL Particles Display
:image :montecarlo

:slide_title Monte Carlo

* **AMCL**: Advanced Monte Carlo Localization** (I've also seen "Augmented" and "Adaptive". Go figure.)
* Why Monte Carlo? That's where the Casinos are!
* Algorithms that incorporate random guesses when a direct solution is hard or not feasible
* Diagram on the board how you would calculate Pi using a Monte Carlo Algorithm
* Note for `PI` it's a very inefficient way to get an accurate result
* But it illustrates the idea of Monte Carlo estimation

:slide_title Particle Filter

* Lets watch a short [Video About Particle FIlters](https://youtu.be/YBeVDxTHiYMz)
* Markov localization means that the new state is dependent only on the previous state (and not the history) and that the probability distributions are 
* Markov localization = state estimation from sensor data
* Instead of "solving" the equation for all data and all points
* Use a Monte-Carlo technique
* Generate a random collection of candidate locations
* Compute the motion
* Adjust the probability of each particle

:slide_title Further references

* [Video about Monte Carlo](https://youtu.be/ELetCV_wX_c)
* You might be interested in these [Advanced Localization Slides](/content/topics/documents/localization.pdf).
* And another useful link: [Where am I](https://medium.com/@NickHortovanyi/where-am-i-6cc0f6608c4c)
* And another great explanation: [Hector Mapping](https://youtu.be/Q4qM-Uzj1SI)


:lecture_end
