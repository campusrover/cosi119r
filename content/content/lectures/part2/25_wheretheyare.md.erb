---
title: How do Robots Localize?
desc: Using landmarks to determine location
hwref: week6
slides: yes
---
<%= include_topic :wheretheyare %>

<slide_break></slide_break>

## Localization

* What exactly is the problem with knowing where you are?
* Remember all of this needs an agreed upon coordinate system!
* How would you do it with your eyes closed?
* Recall **odometry** is like **dead reckoning**
* Lots of noise in the signal; accuracy varies; errors build up

<slide_break></slide_break>

### What kinds of landmarks can be used?

* Lidar detected fixed obstacles
* Vision detected fixed obstacles
* How can one obstacle be distinguished from another?

<slide_break></slide_break>

### Lidar detection

* Robot has a 'map' of fixed obstacles
* Robot compares that map with the apparent, transient, map from Lidar
* Calculates a probability distribution of where it might be on that map
* Process is called AMCL

<slide_break></slide_break>

### Visual Detection

* Robot has a collection of scenes it can recognize.
* Needs to meet certain characteristics for it to work
  * CV (computer vision) algorithms need to be able to identify and differentiate it from other images
  * A coordinate in 3D space is required
  * It needs to stay put and not move
  * Examples: facade of a building, a particular tree, a wall, etc.
  * Bad examples: a parked car; a person
* With each scene is the coordinates that correspond to the recognized scene
* CV is constantly analyzing what is seen by the camera
* As soon as it identifies an image, it can use that to figure out where it is
* Note! It has to also figure out where IT is relative to the image

<slide_break></slide_break>

## Video Interlude

<iframe width="560" height="315" src="https://www.youtube.com/embed/xaeUc1-r9rY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<slide_break></slide_break>

<slide_break></slide_break>

## AMCL

* Adaptive Monte Carlo Localization
* Very sophisticated (and standard) mathematical technique
* Can be used with different kinds of sensors.
* How it work with Lidar
  * Requires a map of Lidar visible obstacles, with a coordinate system, and anchored in the real world
  * Given a stationary robot, and a lidar scan, what does it see?
  * Look for a match on the map
  * Form a probability distribution of where the robot MIGHT be
  * Move the robot a little.
  * Compute what the lidar would see given what is known about the motion
  * Update the probabilities

<slide_break></slide_break>

### SLAM

* What if there is no map yet?
* Simultaneous localization and mapping
* Create a theoretical map based on view of the LIDAR
* Move the robot a little and update the map
* Travel through the relevant region (using e.g. Teleop)
* Use the map to localize, or where there is no map yet, extend the map.

<slide_break></slide_break>

## That's all for today!