---
title: How do Robots Localize?
desc: Using landmarks to determine location
hwref: week8
slides: yes
---
:h2 logistics

* Check-in Questions
* "I am amazed" - Non responsiveness in slack. 
* Participation mid-term grade coming up soon!

:slide_title Localization

* What exactly is the problem with knowing where you are?
* Remember all of this needs an agreed upon coordinate system!
* How would you do it with your eyes closed?
* Recall **odometry** is like **dead reckoning**
* Lots of noise in the signal; accuracy varies; errors build up

:slide_title What kinds of landmarks can be used?

* Lidar detected fixed obstacles
* Vision detected fixed obstacles
* How can one obstacle be distinguished from another?

:slide_title Lidar detection

* Robot has a 'map' of fixed obstacles
* Robot compares that map with the apparent, transient, map from Lidar
* Calculates a probability distribution of where it might be on that map
* Process is called AMCL

:slide_title Visual Detection

* Robot has a collection of scenes it can recognize.
* Needs to meet certain characteristics for it to work
  1. CV (computer vision) algorithms need to be able to identify and differentiate it from other images
  1. A coordinate in 3D space is required
  1. It needs to stay put and not move
  1. Examples: facade of a building, a particular tree, a wall, etc.
  1. Bad examples: a parked car; a person
* With each scene is the coordinates that correspond to the recognized scene
* CV is constantly analyzing what is seen by the camera
* As soon as it identifies an image, it can use that to figure out where it is
* Note! It has to also figure out where it is relative to the image

:slide_title Fiducials

* Standardized image with known dimensions
* Conceptually simple geometrical transformation
* Perspective distortion is used to compute relative pose (orientation and distance)
* Tricky business with TFs and POV!

<iframe width="560" height="315" src="https://www.youtube.com/embed/Y8WEGGbLWlA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

:slide_title AMCL

* Adaptive Monte Carlo Localization
* Very sophisticated (and standard) mathematical technique
* Can be used with different kinds of sensors.
* How it works with Lidar
  1. Requires a map of Lidar visible obstacles, with a coordinate system, and anchored in the real world
  1. Given a stationary robot, and a lidar scan, what does it see?
  1. Look for a match on the map
  1. Form a probability distribution of where the robot MIGHT be
  1. Move the robot a little.
  1. Compute what the lidar would see given what is known about the motion
  1. Update the probabilities

:slide_title SLAM

* What if there is no map yet?
* Simultaneous localization and mapping
* Create a theoretical map based on view of the LIDAR
* Move the robot a little and update the map
* Travel through the relevant region (using e.g. Teleop)
* Use the map to localize, or where there is no map yet, extend the map.

:lecture_end
