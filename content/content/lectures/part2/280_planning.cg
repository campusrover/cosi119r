---
title: Path Planning 
desc: Look a little deeper at how its done
slides: true
---
:h2 Logistics
* Secret code: 

:slide_bigtitle Path Planning

* For now, just focus on a mobile robot like a car
* Goal of path planning: get the robot from where it is to a destination
* Beyond that there are many variations
  1. What kind of map is present?
  2. Are the obstacles encountered known ahead of time, and can they move?

:slide_title Types of maps - Graphs

* Define places where Robot can be (nodes)
* Define which ones are connected (edges)
* Edge information includes
  1. What path to take
  1. What the "cost" would be of taking that path (surface, distance, desirability)
* Planning the route becomes a graph searching problem
* Find the "cheapest" path between two nodes

:slide_title Types of maps - Occupancy Grids

* Divide the "area" into a regular grid
* Indicate whether each "cell" in a grid is occupied or free
* Occupancy Grids can be multi-layer
* For example to indicate
  1. access for different types of vehicles
  1. areas that are free but discouraged
* Treat each cell in the grid as a `node` with 4 or 8 edges

:slide_title A different kind of map: Fiducials

:image :markers

* A specific kind of graphical image combined with an algorithm
* Generally the recognition algorithm includes a tool to create the images

:slide_title Aruco Fiducials

* We have used Ubiqutiy Robotics [aruco_detect](http://wiki.ros.org/aruco_detect)
* Easily recognized by camera using computer vision
* Known dimensions
* Known pose (location in 6d) within a certain coordinate system
* Think of that as the map coordinate system

:slide_title Creating Aruco Fiducials

* Lots of ways, in code or online
* e.g. [Aruco Markers Generator](https://chev.me/arucogen/)
* You can choose the size, the number of bits, and the number of distinct tags


:slide_title Tag Detection

* How do we get the transform between a camera and fiducials?
* Compare the orientation, size and transfor betwen the obsrved image and the known features of the fiducial
* Demo!

:slide_title Tag Placement

* Trade-offs: along the wall, along the ceiling
* How many tags do you need?
* Can you have too many?
* Remember: the tag is not identifying a `thing`
* It is just a point where your real world coordinate system is bound to your robot coordinate system

:slide_title Fiducial Localization

* In general localization means computing the transform between `real world` and `robot` coordinates.
* More specifically we are computing a transform betwen a `map` tf and a `robot_base` tf
* Even more specifically what is the transform between the `pose` of the fiducial and the `pose` of the camera.

:slide_title Lab Notebook Entries

* A coming homework asks that you write a "howto" for our lab notebook
* Here's one about [Localization with Fiducials](https://campus-rover.gitbook.io/lab-notebook/cr-package/navigation/fiducials) from another semester

:slide_title Other Resources
* Example: [fiducial_follow](https://github.com/UbiquityRobotics/demos/tree/master/fiducial_follow)

* Two types of Fiducial Localization

:slide_title Fiducial SLAM

* Detect fideucials in image
* Compute transform between fiducial(s) and camera (and robot)
* Orient a coordinate system corresponding to the real world

:slide_title Fiducial Localization with an existing map

* Predefine a map with fiducials marked on it
* Detect fiducials in camera image
* Find transforms between fiducials and camera
* Localize robot on that map

:lecture_end
